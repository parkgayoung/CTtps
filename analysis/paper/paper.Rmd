---
title: "Title Goes Here"
author:
  -gayoung Park
  - Author Two
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
    bookdown::html_document2:
      fig_caption: yes
      reference_docx: "../templates/template.docx" # Insert path for the DOCX file
bibliography: references.bib
csl: "../templates/journal-of-archaeological-science.csl" # Insert path for the bib-style
abstract: |
  Text of abstract
keywords: |
  keyword 1; keyword 2; keyword 3
highlights: |
  These are the highlights. 
---


<!-- This is the format for text comments that will be ignored during renderings. Do not put R code in these comments because it will not be ignored. -->

```{r, setup, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  echo = FALSE,
  comment = "#>",
  fig.path = "../figures/"
)

#library(CTtps) # Or use devtools::load_all('.', quiet = T) if your code is in script files, rather than as functions in the `/R` diretory

library(here)
```

# Introduction

Here is a citation [@Marwick2017]

# Background

```{r demo, eval = FALSE}
1 + 1
```

# Methods


```{r}
#reading landmarks in tps, code from https://gist.github.com/mrdwab/2062329

read.tps = function(data) {
  # Reads the .tps file format produced by TPSDIG 
  # (http://life.bio.sunysb.edu/morph/ into a single data frame
  # USAGE: R> read.tps("filename.tps")
  a = readLines(data) # so we can do some searching and indexing
  LM = grep("LM", a) # find the line numbers for LM
  ID.ind = grep("ID", a) # find the line numbers for ID
  # and the ID values, SCALE values, and image names
  ID = gsub("(ID=)(.*)", "\\2", grep("ID", a, value=T)) 
  SCALE = gsub("(SCALE=)(.*)", "\\2", grep("SCALE", a, value=T)) 
  images = basename(gsub("(IMAGE=)(.*)", "\\2", a[ID.ind - 1]))
  # FOR EACH LOOP   
  skip = LM # set how many lines to skip
  # and how many rows to read
  nrows = as.numeric(gsub("(LM=)(.*)", "\\2", grep("LM", a, value=T)))
  l = length(LM) # number of loops we want
  
  landmarks = vector("list", l) # create an empty list
  
  for (i in 1:l) {
    landmarks[i] = list(data.frame(
      read.table(file = data, header = F, skip = LM[i],
                 nrows = nrows[i], col.names = c("X", "Y")),
      IMAGE = as.character(images[i]),
      ID = ID[i],
      SCALE = SCALE[i]))
  }
  do.call(rbind, landmarks) # rbind the list items into a data.frame
}

#need to figure out how to read the file inside the project
landmarks <- read.tps(here("analysis/data/raw_data/A_BG_2.tps"))



#Understanding each landmark
#ML: maximum length, tip to bottom, perpendicular to the length axis 1- 7
#BL: body length: tip to the closest wing, perpendicular to the length axis 1- 3 OR 1-10 depending on the artifact
#TL: Tang length, the closest wing from the tip to bottom, perpendicular to the length axis 9 - 7 depending on the artifact
#SL: max stem length, perpendicular to the length axis. Closer tang curveâ€™s middle point from the tip to the most distant point of the basal end  9-7 depending on the artifact
#MW: mid width: dimension from margin to margin at the mid-point of the length 2 - 11 axis, perpendicular to the width axis.
#TW: tang width: dimension between each wing, perpendicular to the width  axis  3 - 10
#SW: stem width: width of the basal end of the point, 5mm above the end  5 - 8

#distance between landmarks(euclidean)

landmark_dist = function(landmarks, pt1, pt2) {
  sqrt(
    (landmarks$X[pt1] - landmarks$X[pt2])^2 + 
      (landmarks$Y[pt1] - landmarks$Y[pt2])^2
  ) * as.numeric(levels(landmarks$SCALE))
}

# distance between two y axis 
vertical_dist = function(landmarks, pt1, pt2) {
  d = abs(landmarks$Y[pt1] - landmarks$Y[pt2])
  d * as.numeric(levels(landmarks$SCALE))
}


#Maximum length of sp: ML, distance between landmark 1-7
ML <- landmark_dist(landmarks, 1, 7)

#Body length of sp is 1-3 or 1-10, depending on each artifact.
bl_dist = function(landmarks) {
  d1 = landmark_dist(landmarks, 1, 3)
  d2 = landmark_dist(landmarks, 1, 10)
  max(d1, d2)
}

BL <- bl_dist(landmarks)



# Tang length of sp: TL, distance between landmark 10-7 or 3-7, (y axis)
tl_dist <- function(landmarks) {
  t1 = vertical_dist(landmarks, 10, 7)
  t2 = vertical_dist(landmarks, 3, 7)
  max(t1, t2)
}

TL <- tl_dist

# Maximum length of stem: SL, distance between landmark 9-7 or 4-7 (y axis)
sl_dist <- function(landmarks) {
  s1 = vertical_dist(landmarks, 9, 7)
  s2 = vertical_dist(landmarks, 4, 7)
  max(s1, s2)
}

SL <- sl_dist

# Mid width: MW, distance between landmark 2-11
MW <- landmark_dist(landmarks, 2, 11)

# Maximum width of Tang: TW, distance between landmark 3-10
TW <- landmark_dist(landmarks, 3, 10)

# Stem width: SW, distance between landmark 5-8
SW <- landmark_dist(landmarks, 5, 8)

#Compare multiple artifacts 
#Open multiple tps files 
#This will need to be changed to read files inside the project
datadir <- here("/analysis/data/raw_data/")
files <- dir(datadir, pattern = "*.tps")

#gather ML and BL of all artifacts
ML = c()
BL = c()
TL = c()
SL = c()
MW = c()
TW = c()
SW = c()
for (i in 1:length(files)) {
  filename <- paste(datadir, files[i], sep = "")
  print(filename)
  landmarks <- read.tps(filename)
  ML <- c(ML, landmark_dist(landmarks, 1, 7))
  BL <- c(BL, bl_dist(landmarks))
  TL <- c(TL, tl_dist(landmarks))
  SL <- c(SL, sl_dist(landmarks))
  MW <- c(MW, landmark_dist(landmarks, 2, 11))
  TW <- c(TW, landmark_dist(landmarks, 3, 10))
  SW <- c(SW, landmark_dist(landmarks, 5, 8))
}

#list of all attributes
df <- data.frame(ML, BL, TL, SL, MW, TW, SW, files)

# Correlations with significance levels
library(Hmisc)
rcorr(ML,BL, type = "pearson") # type can be pearson or spearman


# Coefficient of variation (CV)
library(goeveg)
CV_ML <- cv(ML, na.rm = FALSE) #na.rm: logical. Should missing values be removed?
CV_BL <- cv(BL, na.rm = FALSE)

plot(CV_ML, CV_BL)
```


```{r}

# artifacts from SYG6 site
SYG6_files <- dir(datadir, pattern = "SYG6_*")

ML = c()
BL = c()
TL = c()
SL = c()
MW = c()
TW = c()
SW = c()
for (i in 1:length(SYG6_files)) {
  filename <- paste(datadir, SYG6_files[i], sep = "")
  print(filename)
  landmarks <- read.tps(filename)
  ML <- c(ML, landmark_dist(landmarks, 1, 7))
  BL <- c(BL, bl_dist(landmarks))
  TL <- c(TL, tl_dist(landmarks))
  SL <- c(SL, sl_dist(landmarks))
  MW <- c(MW, landmark_dist(landmarks, 2, 11))
  TW <- c(TW, landmark_dist(landmarks, 3, 10))
  SW <- c(SW, landmark_dist(landmarks, 5, 8))
}


```

# Results

```{r get-data, eval = FALSE}
# Note the path that we need to use to access our data files when rendering this document
my_data <- read.csv(here::here('analysis', 'data', 'raw_data', 'my_csv_file.csv'))
```

# Discussion

# Conclusion

# Acknowledgements

<!-- The following line inserts a page break when the output is MS Word. For page breaks in PDF, use \newpage on its own line.  -->
##### pagebreak

# References 
<!-- The following line ensures the references appear here for the MS Word or HTML output files, rather than right at the end of the document (this will not work for PDF files):  -->
<div id="refs"></div>

##### pagebreak

### Colophon

This report was generated on `r Sys.time()` using the following computational environment and dependencies: 

```{r colophon, cache = FALSE}
# which R packages and versions?
devtools::session_info()
```

The current Git commit details are:

```{r}
# what commit is this file at? 
git2r::repository(here::here())
```
